---
layout: mypost
title: 操作系统导论
categories: [博览群书]
---

中文版：

[豆瓣读书](https://book.douban.com/subject/33463930/)

英文版：

[豆瓣读书](https://book.douban.com/subject/19973015/)

---

## 第1章 关于本书的对话

## 第2章 操作系统介绍

## 第3章 关于虚拟化的对话

## 第4章 抽象：进程

## 第5章 插叙：进程API

## 第6章 机制：受限直接执行

## 第7章 进程调度：介绍

  任何公平（fail）的政策（如RR），即在小规模的时间内将CPU均匀分配到活动进程之间，在周转时间这类指标上表现不佳。事实上，这是固有的权衡：如果你愿意不公平，你可以运行较短的工作直到完成，但是要以响应时间为代价。如果你重视公平性，则响应时间会较短，但会以周转时间为代价。这种权衡在系统中很常见。你不能既拥有你的蛋糕，又吃它。

## 第8章 调度：多级反馈队列

  * 规则 1：如果 A 的优先级 > B 的优先级，运行 A （不运行B）。
  * 规则 2：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B 。
  * 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
  * 规则 4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。
  * 规则 5：经过一段时间S，就将系统中所有工作重新加入最高优先级队列。

## 第9章 调度：比例份额

  彩票调度通过随机值，聪明地做到了按比例分配。步长调度算法能够确定的获得需要的比例。虽然两者都很有趣，但由于一些原因，并没有作为CPU调度程序被广泛使用。一个原因时这两种方式都不能很好得适合I/O[AC97]；另一个原因是其中最难的票数分配问题并没有确定的解决方式。

## 第10章 多处理器调度（高级）

  单队列的方式（SQMS）比较容易构建，负载均衡较好，但在扩展性和缓存亲和度方面有着固有的缺陷。多队列方式（MQMS）又很好的扩展性和缓存亲和度，但实现负载均衡却很困难。

## 第11章 关于CPU虚拟化的总结对话

## 第12章 关于内存虚拟化的对话

## 第13章 抽象：地址空间

  操作系统的一个重要子系统：虚拟内存。虚拟内存负责为程序提供一个巨大的，稀疏的，私有的地址空间的假象，其中保存了程序所有指令和数据。操作系统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转换为物理地址，物理内存根据获得的物理地址去获取所需的信息。操作系统会同时对许多进程执行此操作，并且确保程序之间互相不会受到印象，也不会影响操作系统。

## 第14章 插叙：内存操作API

## 第15章 机制：地址转换

  利用地址转换，操作系统可以控制进程的所有内存访问，确保访问在地址空间的界限内。这个技术高效的关键是硬件支持，硬件快速地将所有内存访问操作中的虚拟地址（进程自己看到的内存位置）转换为物理地址（实际位置）。所有的这一切对进程来说都是透明的，进程并不知道自己使用的内存引用已经被重定位，制造了美妙的假象。

  我们还看到了一种特殊的虚拟化方式,称为基址加界限的动态重定位。基址加界限的虚拟化方式非常高效,因为只需要很少的硬件逻辑,就可以将虚拟地址和基址寄存器加起来,并检查进程产生的地址没有越界。基址加界限也提供了保护,操作系统和硬件的协作,确保没有进程能够访问其地址空间之外的内容。保护肯定是操作系统最重要的目标之一。没有保护,操作系统不可能控制机器(如果进程可以随意修改内存,它们就可以轻松地做出可怕的事情,比如重写陷阱表并完全接管系统)。

  遗憾的是,这个简单的动态重定位技术有效率低下的问题。

## 第16章 分段

### 16.1分段：返化的基址/界限

  一个段只是地址空间里的一个连续定长的区域，在典型的地址空间里有3个逻辑不同的段：代码、栈和堆。分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚拟地址空间中的未使用部分占用物理内存。

  分段解决了一些问题,帮助我们实现了更高效的虚拟内存。不只是动态重定位,通过避免地址空间的逻辑段之间的大量潜在的内存浪费,分段能更好地支持稀疏地址空间。它还很快,因为分段要求的算法很容易,很适合硬件完成,地址转换的开销极小。分段还有一个附加的好处:代码共享。如果代码放在独立的段中,这样的段就可能被多个运行的程序共享。

  但我们已经知道,在内存中分配不同大小的段会导致一些问题,我们希望克服。首先,是我们上面讨论的外部碎片。由于段的大小不同,空闲内存被割裂成各种奇怪的大小,因此满足内存分配请求可能会很难。用户可以尝试采用聪明的算法[W+95],或定期紧凑内存,但问题很根本,难以避免。

  第二个问题也许更重要,分段还是不足以支持更一般化的稀疏地址空间。例如,如果有一个很大但是稀疏的堆,都在一个逻辑段中,整个堆仍然必须完整地加载到内存中。换言之,如果使用地址空间的方式不能很好地匹配底层分段的设计目标,分段就不能很好地工作。

## 第17章 空闲空间管理

## 第18章 分页：介绍

### 18.6 小结

  作为虚拟内存挑战的解决方案。与以前的方法（如分段）相比，分页有许多优点。首先，它不会导致外部碎片，因为分页（按设计）将内存划分为固定大小的单元。其次，它非常灵活，支持稀疏虚拟地址空间。

  然而，实现分页支持而不小心考虑，会导致较慢的机器（有许多额外的内存访问来访问页表）和内存浪费（内存被页表塞满而不是有用的应用程序数据）。

## 第19章 分页：快速地址转换（TLB）

### 19.2 示例：访问数组

  > 提示：尽可能利用缓存
  >
  > 缓存是计算机系统中最基本的性能改进技术之一，一次又ー次地用于让“常见的情况更快”[HPO6]硬件缓存背后的思想是利用指令和数据引用的局部性（ locality）。通常有两种局部性：时间局部性（ temporal locality）和空间局部性（ spatial locality）时间局部性是指，最近访问过的指令或数据项可能很快会再次访问。想想循环中的循环变量或指令，它们被多次反复访问。空间局部性是指，当程序访问内存地址x时，可能很快会访问邻近x的内存。想想遍历某种数组，访问一个接一个的元素。当然，这些性质取决于程序的特点，并不是绝对的定律，而更像是一种经验法则。
  >
  > 硬件缓存，无论是指令、数据还是地址转换（如TLB），都利用了局部性，在小而快的芯片内存倍器中保存一份内存副本。处理器可以先检查缓存中是否存在就近的副本，而不是必须访问（缓慢的）内存未满足请求。如果存在，处理器就可以很快地访问它（例如在几个CPU时钟内），避免花很多时间来访问内存（好多纳秒）。
  >
  > 你可能会疑惑：既然像TLB这样的缓存这么好，为什么不做更大的缓存，装下所有的数据？可惜的是，这里我们遇到了更基本的定律，就像物理定律那样。如果想要快建地线存，它就必须小，因为光建和其他物理限制会起作用。大的缓存注定慢，因此无法实现目的。所以，我们只能用小而快的幾存。剩下的问题就是如何利用好缓存来提升性能。

## 第25章 关于并发的对话

## 第26章 并发：介绍

  * 临界区(critical section )是访问共享资源的一段代码,资源通常是一个变量或教据结构。

  * 竞态条件(race condition)出现在多个执行线程大致同时进入临界区时,它们都试图更新共享的教据结构,导致了令人惊话的(也许是不希望的)结果。

  * 不确定性(indeterminate )程序由一个或多个竞态条件组成,程序的输出因运行而异,具体取决于哪些线程在何时运行。这导致结果不是确定的 (deterministic ),而我们通常期望计算机系统给出确定的结果。

  * 为了避免这些问题,线程应该使用某种互斥(mutual exclusion )原语。这样做可以保证只有一个线程进入临界区,从而避免出现竟态,并产生确定的程序输出。

## 第27章 插叙：线程API

  * **保持简洁**。最重要的一点,线程之间的锁和信号的代码应该尽可能简洁。复杂的线程交互容易产生缺陷。

  * **让线程交互减到最少**。尽量减少线程之间的交互。每次交互都应该想清楚,并用验证过的、正确的方法来实现(很多方法会在后续章节中学习)。

  * **初始化锁和条件变量**。未初始化的代码有时工作正常,有时失败,会产生奇怪的结果。

  * **检查返回值**。当然,任何C和UNIX 的程序,都应该检查返回值,这里也是一样。否则会导致古怪而难以理解的行为,让你尖叫,或者痛苦地。自己的头发。

  * **注意传给线程的参数和返回值**。具体来说,如果传递在找上分配的变量的引引用,可能就是在犯错误。

  * **每个线程都有自己的栈**。类似于上一条,记住每一个线程都有自己的找。因此,线程局部变量应该是线程私有的,其他他线程不应该访问。线程之间共享數据,值要在堆(heap )或者其他全局可访问的位置。

  * **线程之间总是通过条件变量发送信号**。切记不要用标记变量来同步。

  * **多查手册**。尤其是Linux 的pthread手册,有更多的细节、更丰富的內容。请仔细阅读!

## 第28章 锁

  如今真实的锁是如何实现的:一些硬件支持(更加强大的指令)和一些操作系统支持(例如 Solaris的 park()和unpark()原语,Linux的 futex)。当然,细节有所不同,执行这些锁操作的代码通常是高度优化的。

  > 提示：代码越少越好（劳尔定律）
  > 
  > 程序员倾向于吹嘘自己使用大量的代码实现某功能。这样做本质上是不对的。我们应该吹嘘以很少的代码实现给定的任务。简洁的代码更易懂，缺陷更少。正如 Hugh Lauer在讨论构建一个飞行员操作系统时说：“如果给同样这些人两倍的时间，他们可以只用一半的代码来实现”[L81]。我们称之为劳尔定律（Lauer's Law），很值得记住。下次你吹嘘写了多少代码来完成作业时，三思而后行，或者更好的做法是，回去重写，让代码更清断、精简。

## 第29章 基于锁的并发数据结构

  控制流变化时注意获取锁和释放锁；增加并发不一定能提高性能；有性能问题的时候再做优化。关于最后一点，避免不成熟的优化（ premature optimization）对于所有关心性能的开发者都有用。我们让整个应用的某一小部分变快，却没有提高整体性能，其实没有价值。

  > 提示：更多并发不一定更快
  > 
  > 如果方案带来了大量的开销（例如，频繁地获取锁、释放锁），那么高并发就没有什么意义。加果简单的方案很少用到高开销的调用，通常会很有效。增加更多的锁和复杂性可能会适得其反。话虽如此，有一种办法可以获得真知：实现两种方案（简单但少ー点并发，复杂但多一点并发），测试它们的表现。毕竟，你不能在性能上作弊。结果要么更快，要么不快。

  > 提示：当心锁和控制流
  > 
  > 有一个通用建议，对并发代码和其他代码都有用，即注意控制流的变化导致函数返回和退出，或其他错误情况导致函数停止执行。因为很多函数开始就会获得锁，分配内存，或者进行其他一些改变状态这种模式。的操作，如果错误发生，代码需要在返回前恢复各种状态，这容易出错。因此，最好组织好代码，减少这种模式。

  > 建议：避免不成熟的优化（ Knuth定律）
  >
  > 实现并发数据结构时，先从最简单的方案开始，也就是加一把大锁来同步。这样做，你很可能构建了正确的锁。如果发现性能问题，那么就改进方法，只要优化到满足需要即可。正如 Knuth的著名说法“不成熟的优化是所有坏事的根源。”

## 第30章 条件变量

## 第31章 信号量

  信号量是编写并发程序的强大而灵活的原语。

  >提示：简单的笨办法可能更好（Hil定律）
  >
  > 我们不能小看一个概念，即简单的笨办法可能最好。某些时候简单的自旋锁反而是最有效的，因为它容易实现而且高效。虽然读者一写者锁听起来很酷，但是却很复杂，复杂可能意味着慢。因此，总是优先尝试简单的笨办法。
  >
  > 这种受简单吸引的思想，在多个地方都能发现。一个早期来源是 Mark Hill的学位论文[H87]，研究如何为CPU设计缓存。Hill发现简单的直接映射缓存比花哨的集合关联性设计更加有效（一个原因是在缓存中，越简单的设计，越能够更快地查找）。Hill简洁地总结了他的工作：“大而笨更好。”因此我们将这种类似的建议叫作H定律（Hill's Law）。

## 第32章 常见并发问题

  非死锁缺陷

  * 违反原子性缺陷
  * 违反顺序缺陷

  死锁的产生需要如下4个条件[C+71]

  * 互斥：线程对于需要的资源进行互斥的访问（例如一个线程抢到锁）。
  * 持有并等待：线程持有了资源（例如已将持有的锁），同时又在等待其他资源（例如，需要获得的锁）。
  * 非抢占：线程获得的资源（例如锁），不能被抢占。
  * 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。

## 第33章 基于事件的并发（进阶）

## 第34章 并发的总结对话

## 第35章 关于持久性的对话

## 第36章 I/O设备

  利用中断减少CPU开销

  > 提示：中断并非总是比PIO好
  >
  > 尽管中断可以做到计算与IO的重叠，但这仅在慢速设备上有意义。否则，额外的中断处理和上下文切换的代价反而会超过其收益。另外，如果短时间内出现大量的中断，可能会使得系统过載并且引发活锁[MR96]。这种情况下，轮询的方式可以在操作系统自身的调度上提供更多的控制，反而更有效。

  利用DMA进行更高效的数据传送

  DMA引擎是系统中的一个特殊设备，它可以协调完成内存和设备间的数据传递，不需要CPU介入。
  
  DMA工作过程如下。为了能够将数据传送给设备，操作系统会通过编程告诉DMA引擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。在此之后，操作系统就可以处理其他请求了。当DMA的任务完成后，DMA控制器会抛出一个中断来告诉操作系统自己已经完成数据传输。

## 第37章 磁盘驱动器

## 第38章 廉价冗余磁盘阵列（RAID）

## 第39章 插叙：文件和目录

### 39.4 读写文件

> 提示：使用 strace（和类似工具）
>
> straceエ具提供了一种非常棒的方式，来查看程序在做什么。通过运行它，你可以跟踪程序生成的系统调用，查看参数和返回代码，通常可以很好地了解正在发生的事情。
> 
> 该工具还接受一些非常有用的参数。例如，f跟踪所有fork的子进程，t报告每次调用的时间，-e trace=open， close，read，wite只跟踪对这些系统调用的调用，并忽略所有其他调用。还有许多更强大的标志，请阅读手册页，弄清楚如何利用这个奇妙的工具。

### 39.9 删除文件

  unlink()值需要待删除文件的名称，并在成功时返回零。

### 39.13 硬链接

  调用 unlink时，会删除人类可读的名称（正在删除的文件）与给定inode号之间的“链接”，并减少引用计数。只有当引用计数达到零时，文件系统才会释放inode和相关数据块，从而真正“删除”该文件。

### 39.14 符号链接

  还有一种非常有用的链接类型，称为符号链接（ symbolic link），有时称为软链接（soft ink）。事实表明，硬链接有点局限：你不能创建目录的硬链接（因为担心会在目录树中创建一个环）。你不能硬链接到其他磁盘分区中的文件（因为 inode号在特定文件系统中是唯的，而不是跨文件系统），等等。

  符号链接实际上与硬链接完全不同。第一个区别是符号链接本身实际上是一个不同类型的文件。我们已经讨论过常规文件和目录。符号链接是文件系统知道的第三种类型。

  链接指向文件的路径名作为链接文件的数据。如果链接到更长的路径名，链接文件会更大。